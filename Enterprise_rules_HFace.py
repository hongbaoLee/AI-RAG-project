import os
from pathlib import Path
import json
from PyPDF2 import PdfReader
import chromadb
# ä¸å†éœ€è¦é˜¿é‡Œäº‘ embedding å‡½æ•°
# from chromadb.utils import embedding_functions  # ä¸å†ä½¿ç”¨
import dashscope
from dashscope import Generation  # ä»éœ€ç”¨äº Qwen

# æ–°å¢ï¼šHuggingFace embedding æ¨¡å‹
from sentence_transformers import SentenceTransformer

# ==================== é…ç½®åŒºï¼ˆè¯·ä¿®æ”¹è¿™é‡Œï¼‰====================
DASHSCOPE_API_KEY = os.getenv("DASHSCOPE_API_KEY")  # ä»ç”¨äº Qwen
CURRENT_DIR = Path(__file__).parent.absolute()
PDF_PATH = os.path.join(CURRENT_DIR, "exercise2024.pdf")
QWEN_MODEL = "qwen3-max"
# EMBEDDING_MODEL = "text-embedding-v1"  # â† ä¸å†ä½¿ç”¨ï¼Œå·²æ³¨é‡Š

# âš ï¸ è¯·ç¡®ä¿æ­¤è·¯å¾„æŒ‡å‘ä½ ä¸‹è½½çš„ HuggingFace æ¨¡å‹æ–‡ä»¶å¤¹
HF_MODEL_PATH = os.path.join(CURRENT_DIR, "./models/st_paraphrase-multilingual-MiniLM-L12-v2")
CHROMA_DB_PATH = "./chroma_db_company"
# ============================================================

# è®¾ç½® DashScope API Keyï¼ˆä»…ç”¨äº Qwenï¼‰
dashscope.api_key = DASHSCOPE_API_KEY

# ================== Step 1: æå– PDF å¹¶åˆ†æ®µ ==================
def extract_text_from_pdf(pdf_path):
    if not os.path.exists(pdf_path):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ–‡ä»¶: {pdf_path}")
    reader = PdfReader(pdf_path)
    text = ""
    for page in reader.pages:
        text += page.extract_text() or ""
    return text

def split_text(text, chunk_size=300, overlap=50):
    words = text.split()
    chunks = []
    start = 0
    while start < len(words):
        end = start + chunk_size
        chunk = " ".join(words[start:end])
        chunks.append(chunk)
        start = end - overlap
    return [c.strip() for c in chunks if len(c.strip()) > 20]

# ================== Step 2: ä½¿ç”¨æœ¬åœ° HuggingFace æ¨¡å‹è·å– Embedding ==================
# å…¨å±€åŠ è½½æ¨¡å‹ï¼ˆåªåŠ è½½ä¸€æ¬¡ï¼Œæé«˜æ•ˆç‡ï¼‰
print("ğŸ§  æ­£åœ¨åŠ è½½æœ¬åœ° HuggingFace Embedding æ¨¡å‹...")
hf_embedding_model = SentenceTransformer(HF_MODEL_PATH)
print("âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼")

def get_embedding(texts):
    """
    ä½¿ç”¨æœ¬åœ° SentenceTransformer æ¨¡å‹ç”Ÿæˆ embedding
    è¾“å…¥: str æˆ– List[str]
    è¾“å‡º: å•ä¸ªå‘é‡ï¼ˆlistï¼‰æˆ–å‘é‡åˆ—è¡¨ï¼ˆList[list]ï¼‰
    """
    was_single = False
    if isinstance(texts, str):
        texts = [texts]
        was_single = True

    # ç”Ÿæˆ embeddingï¼Œè‡ªåŠ¨å½’ä¸€åŒ–ï¼ˆä¾¿äº cosine ç›¸ä¼¼åº¦è®¡ç®—ï¼‰
    embeddings = hf_embedding_model.encode(
        texts,
        convert_to_numpy=False,  # è¿”å› Python list è€Œé numpy arrayï¼ˆChromaDB å…¼å®¹ï¼‰
        normalize_embeddings=True  # â­ å…³é”®ï¼šå½’ä¸€åŒ–å dot = cosine ä½™å¼¦ç›¸ä¼¼åº¦
    )

    # è½¬ä¸ºæ™®é€š listï¼ˆChromaDB æ¥å— list[float]ï¼‰
    embeddings = [emb.tolist() if hasattr(emb, 'tolist') else emb for emb in embeddings]

    return embeddings[0] if was_single else embeddings

# ================== Step 3: åˆå§‹åŒ– ChromaDBï¼ˆä¸å†ä¾èµ–è¿œç¨‹ embeddingï¼‰==================
client = chromadb.PersistentClient(path=CHROMA_DB_PATH)

# åˆ›å»º collectionï¼Œä¸æŒ‡å®š embedding_functionï¼ˆå› ä¸ºæˆ‘ä»¬è‡ªå·±æä¾› embeddingï¼‰
collection = client.get_or_create_collection(
    name="company_rules",
    metadata={"hnsw:space": "cosine"}  # cosine è·ç¦»ï¼Œä¸ normalize_embeddings=True åŒ¹é…
)

# ================== Step 4: å°† PDF å†…å®¹å†™å…¥å‘é‡åº“ ==================
def load_pdf_to_vector_db(pdf_path):
    print("ğŸ“„ æ­£åœ¨è¯»å– PDF...")
    full_text = extract_text_from_pdf(pdf_path)
    chunks = split_text(full_text, chunk_size=300, overlap=50)
    print(f"âœ… åˆ‡åˆ†ä¸º {len(chunks)} ä¸ªæ®µè½")

    # æ‰¹é‡è·å– embeddingï¼ˆæœ¬åœ°æ¨¡å‹ï¼Œæ— éœ€åˆ†æ‰¹é™åˆ¶ï¼Œä½†ä¿ç•™ batch_size ä»¥é˜²å†…å­˜è¿‡å¤§ï¼‰
    batch_size = 32  # å¯é€‚å½“å¢å¤§
    all_embeddings = []
    for i in range(0, len(chunks), batch_size):
        batch = chunks[i:i + batch_size]
        print(f"ğŸ§  æ­£åœ¨å¤„ç†ç¬¬ {i//batch_size + 1} æ‰¹ Embeddingï¼ˆæœ¬åœ°ï¼‰...")
        embs = get_embedding(batch)
        all_embeddings.extend(embs)

    # å­˜å…¥ ChromaDB
    collection.upsert(
        ids=[f"chunk_{i}" for i in range(len(chunks))],
        documents=chunks,
        embeddings=all_embeddings,
        metadatas=[{"source": os.path.basename(pdf_path), "id": f"chunk_{i}"} for i in range(len(chunks))]
    )
    print("ğŸ’¾ å·²å°†æ–‡æ¡£å­˜å…¥æœ¬åœ°å‘é‡æ•°æ®åº“ï¼")

# ================== Step 5: æ£€ç´¢æœ€ç›¸å…³çš„å†…å®¹ ==================
def retrieve_relevant_context(question, n_results=2):
    print("ğŸ” æ­£åœ¨æ£€ç´¢çŸ¥è¯†åº“...")
    q_emb = get_embedding(question)  # æœ¬åœ° embedding
    results = collection.query(
        query_embeddings=[q_emb],
        n_results=n_results
    )
    return results['documents'][0]  # è¿”å› top 2 æ®µè½

# ================== Step 6: è°ƒç”¨ Qwen ç”Ÿæˆå›ç­” ==================
def call_qwen(prompt):
    try:
        response = Generation.call(
            model=QWEN_MODEL,
            messages=[
                {'role': 'system', 'content': 'ä½ æ˜¯ä¸€ä¸ªä¼ä¸šåˆ¶åº¦é¡¾é—®ï¼Œè¯·æ ¹æ®æä¾›çš„èµ„æ–™å‡†ç¡®å›ç­”é—®é¢˜ã€‚'},
                {'role': 'user', 'content': prompt}
            ],
            temperature=0.5,
            top_p=0.8
        )
        if response.status_code == 200:
            return response.output.choices[0].message.content
        else:
            return f"âŒ è°ƒç”¨å¤±è´¥ï¼š{response.status_code} {response.message}"
    except Exception as e:
        return f"ğŸš¨ è°ƒç”¨å‡ºé”™ï¼š{str(e)}"

# ================== Step 7: ä¸»é—®ç­”é€»è¾‘ ==================
def ask_company_rules(question):
    context = retrieve_relevant_context(question, n_results=2)
    prompt = f"""
ä½ æ˜¯ä¸€åå…¬å¸åˆ¶åº¦ä¸“å®¶ï¼Œè¯·æ ¹æ®ä»¥ä¸‹çœŸå®èµ„æ–™å›ç­”é—®é¢˜ã€‚è¯·å›ç­”ç®€æ´ã€å‡†ç¡®ã€å£è¯­åŒ–ã€‚

ã€å‚è€ƒèµ„æ–™ã€‘
{''.join(f"- {c}\n" for c in context)}

ã€é—®é¢˜ã€‘
{question}

âš ï¸ è¦æ±‚ï¼š
1. å¦‚æœèµ„æ–™ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯´â€œæš‚æ—¶æ— æ³•æ‰¾åˆ°ç›¸å…³ä¿¡æ¯â€ã€‚
2. ä¸è¦ç¼–é€ å†…å®¹ã€‚
3. å›ç­”ç”¨ä¸­æ–‡ã€‚
"""
    print("â˜ï¸ æ­£åœ¨è°ƒç”¨ Qwen å¤§æ¨¡å‹...")
    answer = call_qwen(prompt)
    return answer

# ================== ä¸»ç¨‹åºå…¥å£ ==================
if __name__ == "__main__":
    # ç¬¬ä¸€æ¬¡è¿è¡Œæ—¶åŠ è½½ PDFï¼ˆåªéœ€ä¸€æ¬¡ï¼‰
    if collection.count() == 0:
        print("ğŸ“¥ æ£€æµ‹åˆ°æ•°æ®åº“ä¸ºç©ºï¼Œæ­£åœ¨å¯¼å…¥ PDF æ•°æ®...")
        load_pdf_to_vector_db(PDF_PATH)
    else:
        print(f"ğŸ“Š å·²åŠ è½½ {collection.count()} æ¡æ•°æ®")

    print("\nğŸ’¬ æ¬¢è¿ä½¿ç”¨ã€å…¬å¸åˆ¶åº¦æ™ºèƒ½åŠ©æ‰‹ã€‘ï¼ˆè¾“å…¥ 'quit' é€€å‡ºï¼‰")
    print("ğŸ’¡ ç¤ºä¾‹é—®é¢˜ï¼š")
    print("  â€¢ å¹´å‡æ€ä¹ˆç”³è¯·ï¼Ÿ")
    print("  â€¢ åŠ ç­æœ‰è¡¥è´´å—ï¼Ÿ")
    print("  â€¢ è¯•ç”¨æœŸå¤šä¹…ï¼Ÿ")

    while True:
        question = input("\nâ“ è¯·è¾“å…¥ä½ çš„é—®é¢˜ï¼š").strip()
        if question.lower() == 'quit':
            print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ï¼Œå†è§ï¼")
            break
        if not question:
            continue

        answer = ask_company_rules(question)
        print("\n" + "=" * 60)
        print("ğŸ¤– å›ç­”ï¼š")
        print(answer)
        print("=" * 60)
